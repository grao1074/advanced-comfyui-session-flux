{
    "6": {
        "inputs": {
            "text": " photograph of a young man sitting in a chair in a room looking into the camera ",
            "clip": [
                "38",
                0
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Positive Prompt)"
        }
    },
    "8": {
        "inputs": {
            "samples": [
                "31",
                0
            ],
            "vae": [
                "50",
                0
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "27": {
        "inputs": {
            "width": 1024,
            "height": 1024,
            "batch_size": 1
        },
        "class_type": "EmptySD3LatentImage",
        "_meta": {
            "title": "EmptySD3LatentImage"
        }
    },
    "31": {
        "inputs": {
            "seed": 173805153958775,
            "steps": 30,
            "cfg": 1,
            "sampler_name": "euler",
            "scheduler": "simple",
            "denoise": 1,
            "model": [
                "37",
                0
            ],
            "positive": [
                "41",
                0
            ],
            "negative": [
                "33",
                0
            ],
            "latent_image": [
                "27",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KSampler"
        }
    },
    "33": {
        "inputs": {
            "text": "",
            "clip": [
                "38",
                0
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Negative Prompt)"
        }
    },
    "37": {
        "inputs": {
            "unet_name": "flux1-dev.safetensors",
            "weight_dtype": "fp8_e4m3fn"
        },
        "class_type": "UNETLoader",
        "_meta": {
            "title": "Load Diffusion Model"
        }
    },
    "38": {
        "inputs": {
            "clip_name1": "flux/t5xxl_fp16.safetensors",
            "clip_name2": "ViT-L-14-TEXT-detail-improved-hiT-GmP-HF.safetensors",
            "type": "flux",
            "device": "default"
        },
        "class_type": "DualCLIPLoader",
        "_meta": {
            "title": "DualCLIPLoader"
        }
    },
    "41": {
        "inputs": {
            "guidance": 3.5,
            "conditioning": [
                "46",
                0
            ]
        },
        "class_type": "FluxGuidance",
        "_meta": {
            "title": "FluxGuidance"
        }
    },
    "42": {
        "inputs": {
            "style_model_name": "flux1-redux-dev.safetensors"
        },
        "class_type": "StyleModelLoader",
        "_meta": {
            "title": "Load Style Model"
        }
    },
    "43": {
        "inputs": {
            "clip_name": "siglip-so400m-patch14-384.safetensors"
        },
        "class_type": "CLIPVisionLoader",
        "_meta": {
            "title": "Load CLIP Vision"
        }
    },
    "44": {
        "inputs": {
            "downsampling_factor": 3,
            "downsampling_function": "area",
            "mode": "center crop (square)",
            "weight": 0.8,
            "autocrop_margin": 0.1,
            "conditioning": [
                "6",
                0
            ],
            "style_model": [
                "42",
                0
            ],
            "clip_vision": [
                "43",
                0
            ],
            "image": [
                "155",
                0
            ],
            "mask": [
                "158",
                1
            ]
        },
        "class_type": "ReduxAdvanced",
        "_meta": {
            "title": "ReduxAdvanced"
        }
    },
    "45": {
        "inputs": {
            "downsampling_factor": 3,
            "downsampling_function": "area",
            "mode": "center crop (square)",
            "weight": 1,
            "autocrop_margin": 0.1,
            "conditioning": [
                "44",
                0
            ],
            "style_model": [
                "42",
                0
            ],
            "clip_vision": [
                "43",
                0
            ],
            "image": [
                "156",
                0
            ],
            "mask": [
                "162",
                1
            ]
        },
        "class_type": "ReduxAdvanced",
        "_meta": {
            "title": "ReduxAdvanced"
        }
    },
    "46": {
        "inputs": {
            "downsampling_factor": 3,
            "downsampling_function": "area",
            "mode": "center crop (square)",
            "weight": 0.8,
            "autocrop_margin": 0.1,
            "conditioning": [
                "45",
                0
            ],
            "style_model": [
                "42",
                0
            ],
            "clip_vision": [
                "43",
                0
            ],
            "image": [
                "157",
                0
            ]
        },
        "class_type": "ReduxAdvanced",
        "_meta": {
            "title": "ReduxAdvanced"
        }
    },
    "50": {
        "inputs": {
            "vae_name": "ae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
            "title": "Load VAE"
        }
    },
    "154": {
        "inputs": {
            "filename_prefix": "ComfyUI",
            "images": [
                "8",
                0
            ]
        },
        "class_type": "SaveImage",
        "_meta": {
            "title": "Save Image"
        }
    },
    "155": {
        "inputs": {
            "image": "IMG_20210110_114118 (1).jpg",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    },
    "156": {
        "inputs": {
            "image": "xfit_black-white01.jpg",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    },
    "157": {
        "inputs": {
            "image": "empty-living-room-leds-color-blow-nobody-inside-living-room-led-lights-116241781.webp",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    },
    "158": {
        "inputs": {
            "prompt": "face, hair",
            "threshold": 0.35000000000000003,
            "sam_model": [
                "159",
                0
            ],
            "grounding_dino_model": [
                "160",
                0
            ],
            "image": [
                "155",
                0
            ]
        },
        "class_type": "GroundingDinoSAMSegment (segment anything)",
        "_meta": {
            "title": "GroundingDinoSAMSegment (segment anything)"
        }
    },
    "159": {
        "inputs": {
            "model_name": "sam_vit_b_01ec64.pth",
            "device_mode": "Prefer GPU"
        },
        "class_type": "SAMLoader",
        "_meta": {
            "title": "SAMLoader (Impact)"
        }
    },
    "160": {
        "inputs": {
            "model_name": "GroundingDINO_SwinB (938MB)"
        },
        "class_type": "GroundingDinoModelLoader (segment anything)",
        "_meta": {
            "title": "GroundingDinoModelLoader (segment anything)"
        }
    },
    "161": {
        "inputs": {
            "images": [
                "158",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "162": {
        "inputs": {
            "prompt": "chair",
            "threshold": 0.35000000000000003,
            "sam_model": [
                "159",
                0
            ],
            "grounding_dino_model": [
                "160",
                0
            ],
            "image": [
                "156",
                0
            ]
        },
        "class_type": "GroundingDinoSAMSegment (segment anything)",
        "_meta": {
            "title": "GroundingDinoSAMSegment (segment anything)"
        }
    },
    "163": {
        "inputs": {
            "images": [
                "162",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "164": {
        "inputs": {
            "prompt": "face, hair",
            "threshold": 0.35000000000000003,
            "sam_model": [
                "159",
                0
            ],
            "grounding_dino_model": [
                "160",
                0
            ],
            "image": [
                "8",
                0
            ]
        },
        "class_type": "GroundingDinoSAMSegment (segment anything)",
        "_meta": {
            "title": "GroundingDinoSAMSegment (segment anything)"
        }
    },
    "165": {
        "inputs": {
            "images": [
                "164",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "166": {
        "inputs": {
            "context_expand_pixels": 20,
            "context_expand_factor": 1,
            "fill_mask_holes": true,
            "blur_mask_pixels": 16,
            "invert_mask": false,
            "blend_pixels": 16,
            "rescale_algorithm": "bicubic",
            "mode": "forced size",
            "force_width": 1024,
            "force_height": 1024,
            "rescale_factor": 1,
            "min_width": 512,
            "min_height": 512,
            "max_width": 768,
            "max_height": 768,
            "padding": 32,
            "image": [
                "8",
                0
            ],
            "mask": [
                "164",
                1
            ]
        },
        "class_type": "InpaintCrop",
        "_meta": {
            "title": "✂️ Inpaint Crop"
        }
    },
    "167": {
        "inputs": {
            "images": [
                "166",
                1
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "168": {
        "inputs": {
            "width": 0,
            "height": [
                "175",
                2
            ],
            "interpolation": "lanczos",
            "method": "keep proportion",
            "condition": "always",
            "multiple_of": 0,
            "image": [
                "155",
                0
            ]
        },
        "class_type": "ImageResize+",
        "_meta": {
            "title": "🔧 Image Resize"
        }
    },
    "169": {
        "inputs": {
            "direction": "right",
            "match_image_size": true,
            "image1": [
                "170",
                0
            ],
            "image2": [
                "171",
                0
            ]
        },
        "class_type": "ImageConcanate",
        "_meta": {
            "title": "Image Concatenate"
        }
    },
    "170": {
        "inputs": {
            "mask": [
                "176",
                0
            ]
        },
        "class_type": "MaskToImage",
        "_meta": {
            "title": "Convert Mask to Image"
        }
    },
    "171": {
        "inputs": {
            "width": [
                "168",
                1
            ],
            "height": [
                "168",
                2
            ],
            "batch_size": 1,
            "color": 0
        },
        "class_type": "EmptyImage",
        "_meta": {
            "title": "EmptyImage"
        }
    },
    "172": {
        "inputs": {
            "channel": "red",
            "image": [
                "169",
                0
            ]
        },
        "class_type": "ImageToMask",
        "_meta": {
            "title": "Convert Image to Mask"
        }
    },
    "173": {
        "inputs": {
            "direction": "right",
            "match_image_size": true,
            "image1": [
                "175",
                0
            ],
            "image2": [
                "168",
                0
            ]
        },
        "class_type": "ImageConcanate",
        "_meta": {
            "title": "Image Concatenate"
        }
    },
    "174": {
        "inputs": {
            "mask_opacity": 0.5,
            "mask_color": "255, 0, 255",
            "pass_through": false,
            "image": [
                "173",
                0
            ],
            "mask": [
                "177",
                0
            ]
        },
        "class_type": "ImageAndMaskPreview",
        "_meta": {
            "title": "ImageAndMaskPreview"
        }
    },
    "175": {
        "inputs": {
            "width": 1024,
            "height": 1024,
            "interpolation": "lanczos",
            "method": "keep proportion",
            "condition": "downscale if bigger",
            "multiple_of": 0,
            "image": [
                "166",
                1
            ]
        },
        "class_type": "ImageResize+",
        "_meta": {
            "title": "🔧 Image Resize"
        }
    },
    "176": {
        "inputs": {
            "width": [
                "175",
                1
            ],
            "height": [
                "175",
                2
            ],
            "keep_proportions": true,
            "upscale_method": "nearest-exact",
            "crop": "disabled",
            "mask": [
                "166",
                2
            ]
        },
        "class_type": "ResizeMask",
        "_meta": {
            "title": "Resize Mask"
        }
    },
    "177": {
        "inputs": {
            "kernel_size": 50,
            "sigma": 10,
            "mask": [
                "172",
                0
            ]
        },
        "class_type": "ImpactGaussianBlurMask",
        "_meta": {
            "title": "Gaussian Blur Mask"
        }
    },
    "180": {
        "inputs": {
            "images": [
                "173",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "182": {
        "inputs": {
            "images": [
                "169",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    }
}